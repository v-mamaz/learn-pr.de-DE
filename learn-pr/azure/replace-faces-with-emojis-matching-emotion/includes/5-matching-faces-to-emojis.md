Im letzten Kapitel wurde beschrieben, dass die Datei `shared/mojis.ts` √ºber eine Liste mit Emojis und die zugeh√∂rigen emotionalen Punkte verf√ºgt.

In diesem Kapitel wird der Rest des Codes beschrieben, den wir verwenden, um ein Gesicht einem Emoji zuzuordnen.

Sie lernen Folgendes:

1. Erstellen eines Skripts zum √úbergeben einer URL zum Bild eines Gesichts
2. Berechnen des emotionalen Punkts von Gesichtern im Bild
3. Zuordnen der Gesichter im Bild zu den naheliegendsten Emojis

Abschlie√üend implementieren wir dies in Bezug auf die Funktion dann als Slack-Befehl. Jetzt starten wir aber mit einem einfachen Node-Skript, das Sie in der Befehlszeile ausf√ºhren k√∂nnen:

```bash
node bin/mojify.js <url-of-image-with-face>
```

## <a name="debugging-typescript"></a>Debuggen von TypeScript

Wir schreiben in TypeScript, aber die Ausf√ºhrung erfolgt per JavaScript. Dies erschwert das Debuggen, da wir Breakpoints setzen und in den transpilierten JavaScript-Dateien debuggen m√ºssen, die ggf. schwierig zu lesen sind.

Idealerweise sollte das Schreiben _und_ Debuggen in TypeScript erfolgen.

Die gute Nachricht ist, dass dies mit VS Code bei nur geringem Konfigurationsaufwand m√∂glich ist.

√ñffnen Sie die Datei `launch.json`, indem Sie die Befehlspalette verwenden: `Ctrl+P > Debug: Open launch.json`.

> TODO: Bild

F√ºgen Sie wie folgt eine Konfigurationsoption hinzu:

```json
{
  "type": "node",
  "request": "launch",
  "name": "Mojify",
  "env": {
    "DEBUG": "*"
  },
  "args": [
    "https://pbs.twmedia-drafts.com/profile_images/833970306339446784/83MO53R9_400x400.jpg"
  ],
  "sourceMaps": true,
  "stopOnEntry": false,
  "console": "integratedTerminal",
  "cwd": "${workspaceRoot}",
  "program": "${workspaceRoot}/bin/mojify.js",
  "outFiles": ["${workspaceRoot}/bin/mojify.js"]
}
```

Im Men√º f√ºr das Debuggen wird jetzt die Option `Mojify` angezeigt, mit der das mojify-Skript ausgef√ºhrt und eine URL als Argument √ºbergeben wird. Sie k√∂nnen in der TypeScript-Datei Breakpoints setzen und darin direkt Variablen untersuchen.

## <a name="open-up-binmojists"></a>√ñffnen Sie `bin/mojis.ts`.

Das Ger√ºst f√ºr die Datei mit allen erforderlichen Importen steht bereits:

```typescript
require("dotenv").config();
import fetch from "node-fetch";
import { EmotivePoint, Face, Rect } from "../shared/models";
```

`dotenv` ist ein Hilfsprogrammpaket, mit dem der Inhalt einer ENV-Datei im Stamm Ihres Projekts in Form von Umgebungsvariablen geladen wird. Dies ist hilfreich f√ºr die Entwicklung.

Wir verwenden `node-fetch`, um HTTP-Anforderungen an die Azure-Gesichtserkennungs-API zu senden.

`EmotivePoint` ist eine Hilfsklasse, mit der ein Punkt im _emotionalen Raum_ beschrieben wird. Hierauf gehen wir weiter unten n√§her ein.

`Rect` ist eine Hilfsklasse zum Beschreiben einer rechteckigen Form. Wir nutzen sie, um die Position eines Gesichts in einem Bild zu beschreiben.

`Face` ist eine Hilfsprogrammklasse, mit der die Informationen zum Rechteck und emotionalen Punkt eines Gesichts in einem Bild kombiniert werden.

Im mittleren Bereich der Datei sollten einige Stub-Funktionen angezeigt werden:

```typescript
async function getFaces(imageUrl) {
  //TODO
}

async function createMojifiedImage(imageUrl, faces) {
  //TODO
}
```

Hierbei handelt es sich um die Funktionen, die Sie in dieser und der n√§chsten Lektion gestalten.

Am Ende der Datei sollte dieser Code angezeigt werden:

```typescript
async function main() {
  const [imageUrl] = process.argv.slice(2);
  console.log(imageUrl);
  const faces = await getFaces(imageUrl);
  await createMojifiedImage(imageUrl, faces);
}
main();
```

## <a name="add-the-environment-variables"></a>Hinzuf√ºgen der Umgebungsvariablen

Da wir die Gesichtserkennungs-API aufrufen, m√ºssen wir die zuvor generierten geheimen Schl√ºssel und URLs verwenden und oben in der Datei unter den Importen hinzuf√ºgen:

```typescript
const API_URL = process.env["FACE_API_URL"];
const API_KEY = process.env["FACE_API_KEY"];
```

## <a name="call-the-face-api-with-the-provided-image-and-get-a-response"></a>Aufrufen der Gesichtserkennungs-API mit dem angegebenen Bild und Erhalten einer Antwort

Wir f√ºgen diesen Code oben in der Funktion `getFaces` hinzu, um eine Anforderung an die Gesichtserkennungs-API zu senden.

```typescript
let response = await fetch(API_URL, {
  headers: {
    "Ocp-Apim-Subscription-Key": API_KEY,
    "Content-Type": "application/json"
  },
  method: "POST",
  body: JSON.stringify({ url: imageUrl })
});
let resp = await response.json();
console.log(resp);
```

Im obigen Code wird der Befehl `fetch` verwendet, um eine `POST`-Anforderung an die Gesichtserkennungs-API zu senden.

Wir √ºbergeben den `API_KEY` im Header, damit die Gesichtserkennungs-API √ºber unsere Anforderung informiert ist. Andernfalls wird die Anforderung abgelehnt.

Wir √ºbergeben die `imageUrl`, die von der Gesichtserkennungs-API im Text analysiert werden soll.

Anschlie√üend erhalten wir die Antwort von der API-Anforderung und geben sie aus.

Bei Ausf√ºhrung des Skripts mit:

```bash
node bin/mojify.js <path-to-image>
```

Die JSON-Antwort, die beim √úbergeben dieses Bilds an die Gesichtserkennungs-API zur√ºckgegeben wurde, sollte ausgegeben werden.

## <a name="parse-the-responce"></a>Analysieren der Antwort

Zum Berechnen von Emojis m√ºssen Sie jedes Gesicht, das in der Antwort von der API zur√ºckgegeben wird, in eine Instanz einer `Face`-Klasse konvertieren.

Wir f√ºgen diesen Code direkt nach dem Aufrufen der API in der Funktion `getFaces` hinzu:

```typescript
let faces = [];
for (let f of resp) {
  let scores = new EmotivePoint(f.faceAttributes.emotion);
  let faceRectangle = new Rect(f.faceRectangle);
  let face = new Face(scores, faceRectangle);
  console.log(face.mojiIcon);
  faces.push(face);
}
return faces;
```

- Wir durchlaufen die einzelnen Gesichter, die in der Antwort zur√ºckgegeben werden.
- Wir generieren aus dem zur√ºckgegebenen JSON-Code die Elemente `EmotivePoint`, `Rect` und `Face`.
- Durch die Erstellung der `Face`-Instanz wird das Gesicht mit einem Emoji abgeglichen.
- Um zu ermitteln, f√ºr welches Emoji sich die √úbereinstimmung ergeben hat, geben wir das `mojiicon`-Element aus.

## <a name="try-it-out"></a>Testen

Wenn Sie das Skript jetzt ausf√ºhren, sollte Folgendes durchgef√ºhrt werden:

- √úbergeben des bereitgestellten Bilds √ºber die Gesichtserkennungs-API und Berechnen der Emotion
- Abgleichen der Emotionen mit Emojis
- Ausgeben der Emojis im Terminal

Beispiel:

```bash
node bin/mojify.js <path-to-image>
<path-to-image>
üòï
```
